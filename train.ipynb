{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd27cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] Loss: 0.2605 Train Acc: 91.94%\n",
      "Epoch [2/15] Loss: 0.0833 Train Acc: 96.77%\n",
      "Epoch [3/15] Loss: 0.0621 Train Acc: 97.72%\n",
      "Epoch [4/15] Loss: 0.0462 Train Acc: 98.05%\n",
      "Epoch [5/15] Loss: 0.0409 Train Acc: 98.47%\n",
      "Epoch [6/15] Loss: 0.0337 Train Acc: 98.64%\n",
      "Epoch [7/15] Loss: 0.0263 Train Acc: 99.05%\n",
      "Epoch [8/15] Loss: 0.0189 Train Acc: 99.25%\n",
      "Epoch [9/15] Loss: 0.0218 Train Acc: 99.21%\n",
      "Epoch [10/15] Loss: 0.0175 Train Acc: 99.37%\n",
      "Epoch [11/15] Loss: 0.0132 Train Acc: 99.55%\n",
      "Epoch [12/15] Loss: 0.0078 Train Acc: 99.72%\n",
      "Epoch [13/15] Loss: 0.0151 Train Acc: 99.46%\n",
      "Epoch [14/15] Loss: 0.0089 Train Acc: 99.67%\n",
      "Epoch [15/15] Loss: 0.0046 Train Acc: 99.84%\n",
      "Test Accuracy: 98.64%\n",
      "All weights and biases saved as fixed-point .h files in: C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "DATA_DIR = \"C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/data_fpga\"\n",
    "OUTPUT_H_DIR = \"C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\"\n",
    "os.makedirs(OUTPUT_H_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "LR = 0.001\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "INT_BITS = 6\n",
    "FRAC_BITS = 10\n",
    "\n",
    "# -------------------------------\n",
    "# CUSTOM DATASET CLASS\n",
    "# -------------------------------\n",
    "class NPZDataset(Dataset):\n",
    "    def __init__(self, npz_path):\n",
    "        data = np.load(npz_path)\n",
    "        self.X = data['X'].astype(np.float32) / 255.0  # normalize\n",
    "        self.y = data['y'].astype(np.int64)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.X[idx].transpose(2,0,1))  # HWC -> CHW\n",
    "        y = torch.tensor(self.y[idx])\n",
    "        return x, y\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD DATA\n",
    "# -------------------------------\n",
    "train_dataset = NPZDataset(os.path.join(DATA_DIR, \"train.npz\"))\n",
    "test_dataset  = NPZDataset(os.path.join(DATA_DIR, \"test.npz\"))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "NUM_CLASSES = len(np.unique(train_dataset.y))\n",
    "\n",
    "# -------------------------------\n",
    "# SMALL FPGA-FRIENDLY CNN\n",
    "# -------------------------------\n",
    "class FPGA_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FPGA_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(32*8*8, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------------\n",
    "# TRAINING LOOP\n",
    "# -------------------------------\n",
    "model = FPGA_CNN(NUM_CLASSES).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    acc = correct / total * 100\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Loss: {running_loss/total:.4f} Train Acc: {acc:.2f}%\")\n",
    "\n",
    "# -------------------------------\n",
    "# TEST ACCURACY\n",
    "# -------------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "print(f\"Test Accuracy: {correct/total*100:.2f}%\")\n",
    "\n",
    "# -------------------------------\n",
    "# FIXED-POINT CONVERSION\n",
    "# -------------------------------\n",
    "def float_to_fixed(w, int_bits=INT_BITS, frac_bits=FRAC_BITS):\n",
    "    scale = 2**frac_bits\n",
    "    w_fp = np.round(w * scale).astype(np.int16)\n",
    "    return w_fp\n",
    "\n",
    "def save_hls_array(filename, arr, name):\n",
    "    arr_flat = arr.flatten()\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(f\"const short {name}[] = {{\")\n",
    "        f.write(\",\".join(map(str, arr_flat)))\n",
    "        f.write(\"};\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# EXTRACT AND SAVE WEIGHTS\n",
    "# -------------------------------\n",
    "layers = ['conv1','conv2','conv3','fc1','fc2']\n",
    "for layer_name in layers:\n",
    "    layer = getattr(model, layer_name)\n",
    "    weight_fp = float_to_fixed(layer.weight.detach().cpu().numpy())\n",
    "    bias_fp   = float_to_fixed(layer.bias.detach().cpu().numpy())\n",
    "    save_hls_array(os.path.join(OUTPUT_H_DIR, f\"{layer_name}_weight.h\"), weight_fp, f\"{layer_name}_weight\")\n",
    "    save_hls_array(os.path.join(OUTPUT_H_DIR, f\"{layer_name}_bias.h\"), bias_fp, f\"{layer_name}_bias\")\n",
    "\n",
    "print(\"All weights and biases saved as fixed-point .h files in:\", OUTPUT_H_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751346be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\conv1_weight.h' as weight_t | scale=1024 | max=0.263672 | min=-0.278320\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\conv1_bias.h' as weight_t | scale=1024 | max=0.195312 | min=-0.140625\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\conv2_weight.h' as weight_t | scale=1024 | max=0.378906 | min=-0.397461\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\conv2_bias.h' as weight_t | scale=1024 | max=0.175781 | min=-0.137695\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\conv3_weight.h' as weight_t | scale=1024 | max=0.382812 | min=-0.523438\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\conv3_bias.h' as weight_t | scale=1024 | max=0.070312 | min=-0.123047\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\fc1_weight.h' as weight_t | scale=1024 | max=0.376953 | min=-0.300781\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\fc1_bias.h' as weight_t | scale=1024 | max=0.061523 | min=-0.049805\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\fc2_weight.h' as weight_t | scale=1024 | max=0.221680 | min=-0.250000\n",
      "Saved 'C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\fc2_bias.h' as weight_t | scale=1024 | max=0.110352 | min=-0.130859\n",
      "✅ All weights and biases saved as HLS fixed-point arrays in: C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------\n",
    "OUTPUT_H_DIR = \"C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\"\n",
    "os.makedirs(OUTPUT_H_DIR, exist_ok=True)\n",
    "\n",
    "FRAC_BITS = 10  # Q-format fraction bits\n",
    "\n",
    "# -------------------------------\n",
    "# SAVE HLS WEIGHTS AS weight_t (ap_fixed) COMPATIBLE\n",
    "# -------------------------------\n",
    "def save_hls_array_nd(filename, arr, name, frac_bits=FRAC_BITS):\n",
    "    \"\"\"\n",
    "    Save a numpy array as HLS C-style multi-dimensional array compatible with 'weight_t' (ap_fixed).\n",
    "    Values are scaled to fixed-point and written as float literals.\n",
    "    \"\"\"\n",
    "    scale = 2 ** frac_bits\n",
    "    arr_fp = np.round(arr * scale) / scale  # scale and back to float\n",
    "\n",
    "    # Generate shape string\n",
    "    shape_str = \"\".join(f\"[{d}]\" for d in arr_fp.shape)\n",
    "\n",
    "    # Recursive function to format nested arrays with float literals\n",
    "    def format_array(a):\n",
    "        if a.ndim == 1:\n",
    "            return \"{\" + \",\".join(f\"{x:.6f}\" for x in a) + \"}\"\n",
    "        else:\n",
    "            return \"{\" + \",\".join(format_array(x) for x in a) + \"}\"\n",
    "\n",
    "    # Write to file using 'weight_t'\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(f\"const weight_t {name}{shape_str} = {format_array(arr_fp)};\\n\")\n",
    "\n",
    "    print(f\"Saved '{filename}' as weight_t | scale={scale} | max={arr_fp.max():.6f} | min={arr_fp.min():.6f}\")\n",
    "# -------------------------------\n",
    "# EXTRACT AND SAVE MODEL WEIGHTS\n",
    "# -------------------------------\n",
    "# Example: Replace with your actual PyTorch model\n",
    "# model = MyCNNModel().to('cpu')  # ensure model is on CPU\n",
    "# model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "layers = ['conv1','conv2','conv3','fc1','fc2']\n",
    "\n",
    "for layer_name in layers:\n",
    "    layer = getattr(model, layer_name)\n",
    "    weight_arr = layer.weight.detach().cpu().numpy()\n",
    "    bias_arr   = layer.bias.detach().cpu().numpy()\n",
    "    \n",
    "    save_hls_array_nd(os.path.join(OUTPUT_H_DIR, f\"{layer_name}_weight.h\"), weight_arr, f\"{layer_name}_weight\")\n",
    "    save_hls_array_nd(os.path.join(OUTPUT_H_DIR, f\"{layer_name}_bias.h\"), bias_arr, f\"{layer_name}_bias\")\n",
    "\n",
    "print(\"✅ All weights and biases saved as HLS fixed-point arrays in:\", OUTPUT_H_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_hls_array_nd(filename, arr, name):\n",
    "    \"\"\"\n",
    "    Save a numpy array as HLS C-style multi-dimensional fixed-point array.\n",
    "    Handles conv/fc layers of arbitrary shape.\n",
    "    \"\"\"\n",
    "    # Convert to fixed-point Q6.10\n",
    "    arr_fp = np.round(arr * (2**FRAC_BITS)).astype(np.int16)\n",
    "    \n",
    "    # Determine C-style array shape string\n",
    "    shape_str = \"\".join([f\"[{d}]\" for d in arr_fp.shape])\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(f\"const short {name}{shape_str} = {{\")\n",
    "        \n",
    "        # Recursive function to write nested arrays\n",
    "        def write_nested(a):\n",
    "            if a.ndim == 1:\n",
    "                f.write(\"{\" + \",\".join(map(str, a)) + \"}\")\n",
    "            else:\n",
    "                f.write(\"{\")\n",
    "                for i, sub in enumerate(a):\n",
    "                    write_nested(sub)\n",
    "                    if i != len(a)-1:\n",
    "                        f.write(\",\")\n",
    "                f.write(\"}\")\n",
    "        \n",
    "        write_nested(arr_fp)\n",
    "        f.write(\"};\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103bef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e215e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/hls_weights\\fpga_cnn.pth\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ SAVE THE MODEL\n",
    "# -------------------------------\n",
    "MODEL_PATH = os.path.join(OUTPUT_H_DIR, \"fpga_cnn.pth\")\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(\"Model saved to:\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1bce22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: cat.png\n",
      "  Predicted class: cat\n",
      "  Confidence: 1.0000\n",
      "  Inference time: 1.000 ms\n",
      "\n",
      "Image: dog.png\n",
      "  Predicted class: dog\n",
      "  Confidence: 0.9987\n",
      "  Inference time: 0.999 ms\n",
      "\n",
      "Image: face.jpg\n",
      "  Predicted class: face\n",
      "  Confidence: 1.0000\n",
      "  Inference time: 0.998 ms\n",
      "\n",
      "Image: plane.jpg\n",
      "  Predicted class: plane\n",
      "  Confidence: 0.9962\n",
      "  Inference time: 1.000 ms\n",
      "\n",
      "Image: car.jpg\n",
      "  Predicted class: car\n",
      "  Confidence: 0.9994\n",
      "  Inference time: 0.000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ LOAD MODEL (optional)\n",
    "# -------------------------------\n",
    "model = FPGA_CNN(NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ IMAGE INFERENCE\n",
    "# -------------------------------\n",
    "# List of image paths\n",
    "# List of image paths\n",
    "IMAGE_PATHS = [\n",
    "    \"C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/cat.png\",\n",
    "    \"C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/dog.png\",\n",
    "    \"C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/face.jpg\",\n",
    "    \"C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/plane.jpg\",\n",
    "    \"C:/Users/nvgok/OneDrive/Apps/AISOC/trybest/car.jpg\"\n",
    "]\n",
    "\n",
    "def preprocess_image(img_path, target_size=(32,32)):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img = img.resize(target_size, Image.LANCZOS)\n",
    "    img_np = np.array(img, dtype=np.float32)/255.0   # normalize\n",
    "    img_tensor = torch.tensor(img_np.transpose(2,0,1)).unsqueeze(0)  # CHW + batch\n",
    "    return img_tensor.to(DEVICE)\n",
    "\n",
    "# Make sure class_names is the same order as labels used in dataset\n",
    "class_names = ['face', 'plane', 'car', 'cat', 'dog']\n",
    "# You already have this from dataset preprocessing step\n",
    "# class_names = ['class0', 'class1', ...]  # replace with your actual classes\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for img_path in IMAGE_PATHS:\n",
    "        img_tensor = preprocess_image(img_path)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        output = model(img_tensor)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        pred_class_idx = output.argmax(1).item()\n",
    "        pred_class_name = class_names[pred_class_idx]   # map index to name\n",
    "        pred_score = torch.softmax(output, dim=1)[0, pred_class_idx].item()\n",
    "        inference_time = (end_time - start_time) * 1000  # ms\n",
    "        \n",
    "        print(f\"Image: {os.path.basename(img_path)}\")\n",
    "        print(f\"  Predicted class: {pred_class_name}\")\n",
    "        print(f\"  Confidence: {pred_score:.4f}\")\n",
    "        print(f\"  Inference time: {inference_time:.3f} ms\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "sharedenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
